{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Umair Ahmad\n",
    "# 21i-2081\n",
    "## Umair.Ahmad@Nu.edu.pk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing Assignment #5\n",
    "# Fake News Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from urduhack.preprocessing import normalize_whitespace\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(data,stop_words):\n",
    "    data= normalize_whitespace(data)\n",
    "    data = data.replace('۔',' ')\n",
    "    data = data.replace('،',' ')\n",
    "    data = data.replace('\\n',' ')\n",
    "    data=data.replace('(',' ')\n",
    "    data=data.replace(')',' ')\n",
    "    nlp = spacy.blank('ur')\n",
    "    doc = nlp(data)\n",
    "    cleaned_data =[]\n",
    "    for x in doc:\n",
    "        if str(x) not in stop_words:\n",
    "            cleaned_data.append(str(x))\n",
    "    return cleaned_data\n",
    "\n",
    "Stop_Words=open('C:/Users/Umair/Downloads/NLP assignmnent 5/stopwords-ur.txt', encoding='utf-8').read()\n",
    "Stop_Words=Stop_Words.replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Features Extraction\n",
    "- Function \"get_data\" recive the three arguments Path of for filereading\n",
    "-  Pass list of Stop word if you want to remove stopwords otherwise pass the empty string\n",
    "-  Set BN to True if you want to remove the duplicates from each features otherwise set to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path,stop_words,BN):\n",
    "    sentences=[]\n",
    "    if(\".\" not in path):\n",
    "        dir_names=listdir(path)\n",
    "        for file in dir_names:\n",
    "            doc=open(str(path)+\"/\"+str(file), encoding='utf-8').read()\n",
    "            lst=data_cleaning(doc,stop_words)\n",
    "            if BN == True:\n",
    "                lst = list(set(lst))\n",
    "            sentences=sentences+lst\n",
    "    else:\n",
    "        doc=open(path, encoding='utf-8').read()\n",
    "        lst=data_cleaning(doc,stop_words)\n",
    "        if BN == True:\n",
    "            lst = list(set(lst))\n",
    "        sentences=sentences+lst\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Preparations for Multinomial NB With Stopwords removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49261\n",
      "74100\n"
     ]
    }
   ],
   "source": [
    "MN_Fake_Data=get_data('C:/Users/Umair/Downloads/NLP assignmnent 5/Train/Fake',Stop_Words,False)\n",
    "MN_Real_Data=get_data('C:/Users/Umair/Downloads/NLP assignmnent 5/Train/Real',Stop_Words,False)\n",
    "print(len(MN_Fake_Data))\n",
    "print(len(MN_Real_Data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Preparations for Boolean NB With Stopwords removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33036\n",
      "46513\n"
     ]
    }
   ],
   "source": [
    "BN_Fake_Data=get_data('C:/Users/Umair/Downloads/NLP assignmnent 5/Train/Fake',Stop_Words,True)\n",
    "BN_Real_Data=get_data('C:/Users/Umair/Downloads/NLP assignmnent 5/Train/Real',Stop_Words,True)\n",
    "print(len(BN_Fake_Data))\n",
    "print(len(BN_Real_Data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Preparations for MultiNomial NB Without Stopwords removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87510\n",
      "131014\n"
     ]
    }
   ],
   "source": [
    "MN_Fake_Data_with_Stopwords=get_data('C:/Users/Umair/Downloads/NLP assignmnent 5/Train/Fake',\"\",False)\n",
    "MN_Real_Data_with_Stopwords=get_data('C:/Users/Umair/Downloads/NLP assignmnent 5/Train/Real',\"\",False)\n",
    "print(len(MN_Fake_Data_with_Stopwords))\n",
    "print(len(MN_Real_Data_with_Stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Preparations for Boolean NB Without Stopwords removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44431\n",
      "61128\n"
     ]
    }
   ],
   "source": [
    "BN_Fake_Data_with_Stopwords=get_data('C:/Users/Umair/Downloads/NLP assignmnent 5/Train/Fake',\"\",True)\n",
    "BN_Real_Data_with_Stopwords=get_data('C:/Users/Umair/Downloads/NLP assignmnent 5/Train/Real',\"\",True)\n",
    "print(len(BN_Fake_Data_with_Stopwords))\n",
    "print(len(BN_Real_Data_with_Stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior Calculation for Fake and Real Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45141065830721006\n",
      "0.54858934169279\n"
     ]
    }
   ],
   "source": [
    "Fake_train_dir=listdir('C:/Users/Umair/Downloads/NLP assignmnent 5/Train/Fake')\n",
    "Real_train_dir=listdir('C:/Users/Umair/Downloads/NLP assignmnent 5/Train/Real')\n",
    "Prior_of_Train_Fake=len(Fake_train_dir)/(len(Fake_train_dir)+len(Real_train_dir))\n",
    "Prior_of_Train_Real=len(Real_train_dir)/(len(Fake_train_dir)+len(Real_train_dir))\n",
    "print(Prior_of_Train_Fake)\n",
    "print(Prior_of_Train_Real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traning of Features\n",
    "- \"Traning\" function receive the two arguments Fake Data and Real Data \n",
    "- Returns the Tranined Conditional Probabilities of the given data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Traning(Fake_data,Real_data):\n",
    "    wordsFreq_fake = defaultdict(float)\n",
    "    wordsFreq_real = defaultdict(float)\n",
    "    cond_prob_fake=defaultdict(float)\n",
    "    cond_prob_real=defaultdict(float)\n",
    "    Vocab=defaultdict(float)\n",
    "    for word in Fake_data:\n",
    "        wordsFreq_fake[str(word)]+=1\n",
    "        Vocab[str(word)]+=1\n",
    "    for word in Real_data:\n",
    "        wordsFreq_real[str(word)]+=1\n",
    "        Vocab[str(word)]+=1\n",
    "    for key,value in Vocab.items():\n",
    "        cond_prob_fake[str(key)]=(wordsFreq_fake[str(key)]+1)/(len(Fake_data)+len(Vocab))\n",
    "        cond_prob_real[str(key)]=(wordsFreq_real[str(key)]+1)/(len(Real_data)+len(Vocab))\n",
    "    return cond_prob_real,cond_prob_fake\n",
    "\n",
    "MN_cond_prob_real,MN_cond_prob_fake=Traning(MN_Fake_Data,MN_Real_Data)\n",
    "BN_cond_prob_real,BN_cond_prob_fake=Traning(BN_Fake_Data,BN_Real_Data)\n",
    "MN_cond_prob_real_SW,MN_cond_prob_fake_SW=Traning(MN_Fake_Data_with_Stopwords,MN_Real_Data_with_Stopwords)\n",
    "BN_cond_prob_real_SW,BN_cond_prob_fake_SW=Traning(BN_Fake_Data_with_Stopwords,BN_Real_Data_with_Stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Sorted Multinomial NB Real Conditional Probabilties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uni_Grams</th>\n",
       "      <th>Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>نہیں</td>\n",
       "      <td>0.006826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>پاکستان</td>\n",
       "      <td>0.005527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>کہا</td>\n",
       "      <td>0.004228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>بعد</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>ساتھ</td>\n",
       "      <td>0.003544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7974</th>\n",
       "      <td>وئير</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5558</th>\n",
       "      <td>تيرہ</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7977</th>\n",
       "      <td>ڈيبٹ</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5555</th>\n",
       "      <td>يونیورس</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7989</th>\n",
       "      <td>سوڈيم</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13654 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Uni_Grams      Freq\n",
       "61        نہیں  0.006826\n",
       "17     پاکستان  0.005527\n",
       "136        کہا  0.004228\n",
       "6          بعد  0.004000\n",
       "252       ساتھ  0.003544\n",
       "...        ...       ...\n",
       "7974      وئير  0.000011\n",
       "5558      تيرہ  0.000011\n",
       "7977      ڈيبٹ  0.000011\n",
       "5555   يونیورس  0.000011\n",
       "7989     سوڈيم  0.000011\n",
       "\n",
       "[13654 rows x 2 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_gram_freq=pd.DataFrame(MN_cond_prob_real.items(), columns=['Uni_Grams', 'Freq'])\n",
    "uni_gram_freq=uni_gram_freq.sort_values('Freq', ascending=False)\n",
    "uni_gram_freq.to_csv(r'MN_cond_prob_real.csv')\n",
    "uni_gram_freq  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Sorted Multinomial NB Fake Conditional Probabilties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uni_Grams</th>\n",
       "      <th>Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>پاکستان</td>\n",
       "      <td>0.006882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>نہیں</td>\n",
       "      <td>0.006088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>ساتھ</td>\n",
       "      <td>0.004148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>مطابق</td>\n",
       "      <td>0.003894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ہونے</td>\n",
       "      <td>0.003751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10561</th>\n",
       "      <td>محال</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10560</th>\n",
       "      <td>جینا</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10559</th>\n",
       "      <td>پڑجاتی</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10558</th>\n",
       "      <td>ایئرکنڈیشنرکی</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13653</th>\n",
       "      <td>موٹرائزڈ</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13654 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Uni_Grams      Freq\n",
       "17           پاکستان  0.006882\n",
       "61              نہیں  0.006088\n",
       "252             ساتھ  0.004148\n",
       "102            مطابق  0.003894\n",
       "41              ہونے  0.003751\n",
       "...              ...       ...\n",
       "10561           محال  0.000016\n",
       "10560           جینا  0.000016\n",
       "10559         پڑجاتی  0.000016\n",
       "10558  ایئرکنڈیشنرکی  0.000016\n",
       "13653       موٹرائزڈ  0.000016\n",
       "\n",
       "[13654 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_gram_freq=pd.DataFrame(MN_cond_prob_fake.items(), columns=['Uni_Grams', 'Freq'])\n",
    "uni_gram_freq=uni_gram_freq.sort_values('Freq', ascending=False)\n",
    "uni_gram_freq.to_csv(r'MN_cond_prob_fake.csv')\n",
    "uni_gram_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Sorted Boolean NB Real Conditional Probabilties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uni_Grams</th>\n",
       "      <th>Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>نہیں</td>\n",
       "      <td>0.003507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>بعد</td>\n",
       "      <td>0.003108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>مطابق</td>\n",
       "      <td>0.002742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>کہا</td>\n",
       "      <td>0.002742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>ہونے</td>\n",
       "      <td>0.002576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7735</th>\n",
       "      <td>پرل</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7736</th>\n",
       "      <td>8ماڈلز</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7737</th>\n",
       "      <td>7روپے</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7738</th>\n",
       "      <td>ہيڈ</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8940</th>\n",
       "      <td>پرجوش</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13654 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Uni_Grams      Freq\n",
       "52        نہیں  0.003507\n",
       "120        بعد  0.003108\n",
       "57       مطابق  0.002742\n",
       "15         کہا  0.002742\n",
       "92        ہونے  0.002576\n",
       "...        ...       ...\n",
       "7735       پرل  0.000017\n",
       "7736    8ماڈلز  0.000017\n",
       "7737     7روپے  0.000017\n",
       "7738       ہيڈ  0.000017\n",
       "8940     پرجوش  0.000017\n",
       "\n",
       "[13654 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_gram_freq=pd.DataFrame(BN_cond_prob_real.items(), columns=['Uni_Grams', 'Freq'])\n",
    "uni_gram_freq=uni_gram_freq.sort_values('Freq', ascending=False)\n",
    "uni_gram_freq.to_csv(r'BN_cond_prob_real.csv')\n",
    "uni_gram_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Sorted Boolean NB Fake Conditional Probabilties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uni_Grams</th>\n",
       "      <th>Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>نہیں</td>\n",
       "      <td>0.003598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>مطابق</td>\n",
       "      <td>0.003256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>ہونے</td>\n",
       "      <td>0.003127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>بعد</td>\n",
       "      <td>0.002977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>دیا</td>\n",
       "      <td>0.002784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10561</th>\n",
       "      <td>ناقابلِ</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10560</th>\n",
       "      <td>سینٹرہرجگہ</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10559</th>\n",
       "      <td>ایئرکنڈیشنرکو</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10558</th>\n",
       "      <td>محال</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13653</th>\n",
       "      <td>بھنویں</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13654 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Uni_Grams      Freq\n",
       "52              نہیں  0.003598\n",
       "57             مطابق  0.003256\n",
       "92              ہونے  0.003127\n",
       "120              بعد  0.002977\n",
       "473              دیا  0.002784\n",
       "...              ...       ...\n",
       "10561        ناقابلِ  0.000021\n",
       "10560     سینٹرہرجگہ  0.000021\n",
       "10559  ایئرکنڈیشنرکو  0.000021\n",
       "10558           محال  0.000021\n",
       "13653         بھنویں  0.000021\n",
       "\n",
       "[13654 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_gram_freq=pd.DataFrame(BN_cond_prob_fake.items(), columns=['Uni_Grams', 'Freq'])\n",
    "uni_gram_freq=uni_gram_freq.sort_values('Freq', ascending=False)\n",
    "uni_gram_freq.to_csv(r'BN_cond_prob_fake.csv')\n",
    "uni_gram_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing of TestData\n",
    "- Function \"Testing\" receive the Conditional probabilties and Prior of the both classes \n",
    "- Return the Predicited Label from log probabilties "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Testing(cond_prob_real,cond_prob_fake,Prior_of_Fake,Prior_of_Real,text):\n",
    "    score={\"Real\":0,\"Fake\":0}\n",
    "    score[\"Real\"]=math.log(Prior_of_Real)\n",
    "    score[\"Fake\"]=math.log(Prior_of_Fake)\n",
    "    for x in text:\n",
    "        if cond_prob_real[str(x)]>0:\n",
    "            score[\"Real\"]+=math.log(cond_prob_real[str(x)])\n",
    "        if cond_prob_fake[str(x)]>0:\n",
    "            score[\"Fake\"]+=math.log(cond_prob_fake[str(x)])\n",
    "    if score[\"Real\"]>score[\"Fake\"]:\n",
    "        return \"Real\"\n",
    "    else:\n",
    "        return \"Fake\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Labels of all the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fake_path='C:/Users/Umair/Downloads/NLP assignmnent 5/Test/Fake'\n",
    "Real_path='C:/Users/Umair/Downloads/NLP assignmnent 5/Test/Real'\n",
    "Fake_dir_names=listdir(Fake_path)\n",
    "Real_dir_names=listdir(Real_path)\n",
    "\n",
    "def cal_labels(real_cond,fake_cond,fake_prior,real_prior,stop_words,BN):\n",
    "    Ypre=[]\n",
    "    for x in Fake_dir_names:\n",
    "        text=get_data(Fake_path+\"/\"+x,stop_words,BN)\n",
    "        ypred=Testing(real_cond,fake_cond,fake_prior,real_prior,text)\n",
    "        Ypre.append(ypred) \n",
    "    for x in Real_dir_names:\n",
    "        text=get_data(Real_path+\"/\"+x,stop_words,BN)\n",
    "        ypred=Testing(real_cond,fake_cond,fake_prior,real_prior,text)\n",
    "        Ypre.append(ypred)\n",
    "    return Ypre\n",
    "\n",
    "MN_Ypre=cal_labels(MN_cond_prob_real,MN_cond_prob_fake,Prior_of_Train_Fake,Prior_of_Train_Real,Stop_Words,False)\n",
    "BN_Ypre=cal_labels(BN_cond_prob_real,BN_cond_prob_fake,Prior_of_Train_Fake,Prior_of_Train_Real,Stop_Words,True)\n",
    "MN_Ypre_SW=cal_labels(MN_cond_prob_real_SW,MN_cond_prob_fake_SW,Prior_of_Train_Fake,Prior_of_Train_Real,\"\",False)\n",
    "BN_Ypre_SW=cal_labels(BN_cond_prob_real_SW,BN_cond_prob_fake_SW,Prior_of_Train_Fake,Prior_of_Train_Real,\"\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Anaylsis\n",
    "After seeing the results of \n",
    "- Na¨ıve Bayes classifier\n",
    "- Boolean Na¨ıve Bayes classifier\n",
    "- Experiment with/without using stop words\n",
    "\n",
    "Metrics for evaluating performance of this classifier are precision,recall, f1-score and accuracy.\n",
    "After Traning of a Na¨ıve Bayes classifier on the data set provided on all four combination mentioned above.\n",
    "These trained model is tested on the testset of Fake and Real new.\n",
    "\n",
    "- Train Dataset(Real=350,Fake=288)\n",
    "- Test Dataset (Real=150,Fake=262)\n",
    "\n",
    "All the classification report are shown below also the average accuracy score of all the four trained models are\n",
    "\n",
    "- **Accuracy Score of Multinomial NB With    Stop Words:    0.70**\n",
    "- **Accuracy Score of Boolean     NB With    Stop Words:    0.78**\n",
    "- **Accuracy Score of Multinomial NB Without Stop Words:    0.73**\n",
    "- **Accuracy Score of Boolean     NB Without Stop Words:    0.79**\n",
    "\n",
    "Rest of the Evaluation measures Precision,Recall and F1 measures are shown below\n",
    "\n",
    "## Conculsion \n",
    "We can achive good results by choosing Boolean Naive Bayes without stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report of Accuracy, Precision, Recall and F1 Measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Multinomial NB With    Stop Words:    0.6946564885496184\n",
      "Accuracy Score of Boolean     NB With    Stop Words:    0.7748091603053435\n",
      "Accuracy Score of Multinomial NB Without Stop Words:    0.7290076335877863\n",
      "Accuracy Score of Boolean     NB Without Stop Words:    0.7824427480916031\n"
     ]
    }
   ],
   "source": [
    "y_Real = [\"Real\"] * len(Real_dir_names)\n",
    "y_Fake = [\"Fake\"] * len(Fake_dir_names)\n",
    "Ytest=y_Fake+y_Real\n",
    "MN_acc=accuracy_score(Ytest, MN_Ypre)\n",
    "BN_acc=accuracy_score(Ytest, BN_Ypre)\n",
    "MN_acc_SW=accuracy_score(Ytest, MN_Ypre_SW)\n",
    "BN_acc_SW=accuracy_score(Ytest, BN_Ypre_SW)\n",
    "print(\"Accuracy Score of Multinomial NB With    Stop Words:    \"+str(MN_acc))\n",
    "print(\"Accuracy Score of Boolean     NB With    Stop Words:    \"+str(BN_acc))\n",
    "print(\"Accuracy Score of Multinomial NB Without Stop Words:    \"+str(MN_acc_SW))\n",
    "print(\"Accuracy Score of Boolean     NB Without Stop Words:    \"+str(BN_acc_SW))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report of Multinomial NB With Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.65      0.62      0.63       112\n",
      "        Real       0.72      0.75      0.74       150\n",
      "\n",
      "    accuracy                           0.69       262\n",
      "   macro avg       0.69      0.68      0.69       262\n",
      "weighted avg       0.69      0.69      0.69       262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = [\"Fake\", \"Real\"]\n",
    "print(classification_report(Ytest, MN_Ypre, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report of Boolean NB With Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.79      0.64      0.71       112\n",
      "        Real       0.77      0.87      0.82       150\n",
      "\n",
      "    accuracy                           0.77       262\n",
      "   macro avg       0.78      0.76      0.76       262\n",
      "weighted avg       0.78      0.77      0.77       262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Ytest, BN_Ypre, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report of Multinomial NB Without Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.70      0.64      0.67       112\n",
      "        Real       0.75      0.79      0.77       150\n",
      "\n",
      "    accuracy                           0.73       262\n",
      "   macro avg       0.72      0.72      0.72       262\n",
      "weighted avg       0.73      0.73      0.73       262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Ytest, MN_Ypre_SW, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report of Boolean NB Without Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.81      0.64      0.72       112\n",
      "        Real       0.77      0.89      0.82       150\n",
      "\n",
      "    accuracy                           0.78       262\n",
      "   macro avg       0.79      0.76      0.77       262\n",
      "weighted avg       0.79      0.78      0.78       262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Ytest, BN_Ypre_SW, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
